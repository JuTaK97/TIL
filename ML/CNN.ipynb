{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPq39BiR4NGXw+ZNoOzuaMy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pDpO_CiW2Ggr"},"source":["# Convolutional Neural Network\n","1. MLP의 한계 <br />\n","이미지 등을 처리할 때, MLP는 일렬로 된 벡터를 처리하게 된다. 이때 두 가지 문제가 발생한다. <br />\n","첫 번째. 이미지의 공간 정보가 사라진다.<br />\n","두 번째. 몇 가지 픽셀 값만 바뀌어도, 단순히 평행이동만 한 거여도 결과가 크게 달라진다.<br />\n","\n","  그래서 kernel, 혹은 filter로 이미지와 convolution 하는 방법을 사용한다."]},{"cell_type":"markdown","metadata":{"id":"bjIUanoy4Q_p"},"source":["## 1. 간단한 CNN 모델 만들기"]},{"cell_type":"code","metadata":{"id":"EhteiXjOtkog","executionInfo":{"status":"ok","timestamp":1633696248255,"user_tz":-540,"elapsed":26550,"user":{"displayName":"주현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5ltk6mU4Acire5podT_1jZ1HY_FA1wdtKouHBCA=s64","userId":"04151192621211208729"}}},"source":["import torch\n","import torch.nn as nn"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L1RjSoET4g4w","executionInfo":{"status":"ok","timestamp":1633697003440,"user_tz":-540,"elapsed":966,"user":{"displayName":"주현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5ltk6mU4Acire5podT_1jZ1HY_FA1wdtKouHBCA=s64","userId":"04151192621211208729"}},"outputId":"67ed9428-a452-4b67-ebb5-2630aebcc07a"},"source":["inputs = torch.Tensor(1, 1, 28, 28)   # 1개, 1채널, 28x28\n","\n","conv1 = nn.Conv2d(1, 32, 3, padding=1)                # 입력 1채널, 출력 32채널, 커널 크기 3, 패딩 1\n","conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)   # 입력 32채널, 출력 32채널, 커널 크기 3, 패딩 1\n","pool = nn.MaxPool2d(2)    # 커널 사이즈랑 stride 모두 2\n","\n","print('최초', inputs.shape)                  # [1, 1, 28, 28]\n","out = conv1(inputs)\n","print('첫 번째 합성망 통과', out.shape)      # [1, 32, 28, 28]   패딩으로 크기 보존됐고 출력 채널은 32로 설정했었다. (그러면 커널이 32종류인건가?)\n","out = pool(out)\n","print('풀링', out.shape)                     # [1, 32, 14, 14]   pooling으로 크기 절반으로 줄었다.\n","out = conv2(out)\n","print('두 번째 합성망 통과', out.shape)      # [1, 64, 14, 14]   패딩으로 크기 보존, 출력은 64개 채널\n","out = pool(out)\n","print('풀링', out.shape)                     # [1, 64,  7,  7]   pooling으로 크기 절반으로 줄었다.\n","\n","\n","out = out.view(out.size(0), -1)              # 배치 차원 빼고 일자로 펼친다.\n","print('일자로 펼치기', out.shape)\n","fullyConnect = nn.Linear(out.shape[1], 10)   # out을 (배치,10) 벡터로 바꾸는 Fully Connected 층\n","out = fullyConnect(out)\n","print('전결망 통과', out.shape)\n","\n"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["최초 torch.Size([1, 1, 28, 28])\n","첫 번째 합성망 통과 torch.Size([1, 32, 28, 28])\n","풀링 torch.Size([1, 32, 14, 14])\n","두 번째 합성망 통과 torch.Size([1, 64, 14, 14])\n","풀링 torch.Size([1, 64, 7, 7])\n","일자로 펼치기 torch.Size([1, 3136])\n","전결망 통과 torch.Size([1, 10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"TeDIsMB67o-p"},"source":["##2. CNN으로 MNIST 분류하기"]},{"cell_type":"markdown","metadata":{"id":"avtaormo72lJ"},"source":["#### 2.1 초기 세팅"]},{"cell_type":"code","metadata":{"id":"lGoMLpxZ7rHx","executionInfo":{"status":"ok","timestamp":1633697159102,"user_tz":-540,"elapsed":289,"user":{"displayName":"주현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5ltk6mU4Acire5podT_1jZ1HY_FA1wdtKouHBCA=s64","userId":"04151192621211208729"}}},"source":["import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.init\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","torch.manual_seed(777)\n","\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5CLJluVK75vQ"},"source":["####2.2 상수 설정 및 데이터 로드"]},{"cell_type":"code","metadata":{"id":"CER_QjgX70gx","executionInfo":{"status":"ok","timestamp":1633697161069,"user_tz":-540,"elapsed":1,"user":{"displayName":"주현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5ltk6mU4Acire5podT_1jZ1HY_FA1wdtKouHBCA=s64","userId":"04151192621211208729"}}},"source":["learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 100\n","\n","mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n","                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n","                          transform=transforms.ToTensor(), # 텐서로 변환\n","                          download=True)\n","\n","mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n","                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n","                         transform=transforms.ToTensor(), # 텐서로 변환\n","                         download=True)\n","data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n","                                          batch_size=batch_size,\n","                                          shuffle=True,\n","                                          drop_last=True)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DwM_Rd1g8AvA"},"source":["####2.3 class로 CNN model 설계"]},{"cell_type":"code","metadata":{"id":"mCbfLmMA8JL_"},"source":["class CNN(torch.nn.Module) :\n","  def __init__(self) :\n","    super(CNN, self).__init__()\n","\n","    self.layer1 = torch.nn.Sequential(\n","          torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","          torch.nn.ReLU(),\n","          torch.nn.MaxPool2d(2)\n","    )\n","    self.layer2 = torch.nn.Sequential(\n","          torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","          torch.nn.ReLU(),\n","          torch.nn.MaxPool2d(2)\n","    )\n","    self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)"],"execution_count":null,"outputs":[]}]}